{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T06:38:22.392941Z",
     "start_time": "2025-04-04T06:38:21.153438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "id": "6895df999294ae7b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T06:38:42.527467Z",
     "start_time": "2025-04-04T06:38:42.510031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def view_Jaco_ddpm(images_list, heatmaps_list, threshold = 0.9, view_image = True):\n",
    "    if view_image:\n",
    "        for idx, (image, heatmap) in enumerate(zip(images_list, heatmaps_list)):\n",
    "            fig, axes = plt.subplots(1, 2, figsize = (5,10))\n",
    "            axes[0].imshow(heatmap.cpu().squeeze().numpy(), cmap='viridis')\n",
    "            axes[1].imshow(image.cpu().detach().squeeze().numpy(), cmap = 'gray', interpolation = 'none')\n",
    "            axes[0].axis('off')\n",
    "            axes[1].axis('off')\n",
    "            plt.title(f'{999-idx} time step Jacobian')\n",
    "            plt.show()\n",
    "\n",
    "    patch_size_list = []\n",
    "    for idx, heatmap in enumerate(heatmaps_list):\n",
    "        patch_size = 0\n",
    "\n",
    "        heatmap_normalized = heatmap / torch.max(heatmap.abs())\n",
    "\n",
    "        ts = 0.01  # 1% of maximum gradient\n",
    "        significant_mask = heatmap_normalized > ts\n",
    "\n",
    "        heatmap_normalized = heatmap_normalized * significant_mask\n",
    "\n",
    "        for size in range(13):\n",
    "            in_patches = heatmap_normalized[0,14-size-1:14+size+2,14-size-1:14+size+2]\n",
    "            patch_influence = in_patches.abs().sum() / heatmap_normalized.abs().sum()\n",
    "            if patch_influence.item() > threshold:\n",
    "                patch_size = in_patches.shape[-1]\n",
    "                patch_size_list.append(patch_size)\n",
    "                break\n",
    "\n",
    "    return patch_size_list\n",
    "\n",
    "def view_Jaco_ddim(images_list, heatmaps_list, threshold = 0.9, view_image=True):\n",
    "\n",
    "    if view_image:\n",
    "        for idx, (image, heatmap) in enumerate(zip(images_list, heatmaps_list)):\n",
    "            fig, axes = plt.subplots(1, 2, figsize = (5,10))\n",
    "            axes[0].imshow(heatmap.cpu().squeeze().numpy(), cmap='viridis')\n",
    "            axes[1].imshow(image.cpu().detach().squeeze().numpy(), cmap = 'gray', interpolation = 'none')\n",
    "            axes[0].axis('off')\n",
    "            axes[1].axis('off')\n",
    "            plt.title(f'{49-idx} time step Jacobian')\n",
    "            plt.show()\n",
    "\n",
    "    patch_size_list = []\n",
    "    for idx, heatmap in enumerate(heatmaps_list):\n",
    "        patch_size = 0\n",
    "\n",
    "        heatmap_normalized = heatmap / torch.max(heatmap)\n",
    "\n",
    "        ts = 0.01  # 1% of maximum gradient\n",
    "        significant_mask = heatmap_normalized > ts\n",
    "\n",
    "        heatmap_normalized = heatmap_normalized * significant_mask\n",
    "\n",
    "        for size in range(13):\n",
    "            in_patches = heatmap_normalized[0,14-size-1:14+size+2,14-size-1:14+size+2]\n",
    "            patch_influence = in_patches.abs().sum() / heatmap_normalized.abs().sum()\n",
    "            if patch_influence.item() > threshold:\n",
    "                patch_size = in_patches.shape[-1]\n",
    "                patch_size_list.append(patch_size)\n",
    "                break\n",
    "\n",
    "    return patch_size_list\n",
    "\n",
    "def view_Jaco_ddim1(images_list, heatmaps_list, view_image=True):\n",
    "\n",
    "    if view_image:\n",
    "        for idx, (image, heatmap) in enumerate(zip(images_list, heatmaps_list)):\n",
    "            fig, axes = plt.subplots(1, 2, figsize = (5,10))\n",
    "            axes[0].imshow(heatmap.cpu().squeeze().numpy(), cmap='viridis')\n",
    "            axes[1].imshow(image.cpu().detach().squeeze().numpy(), cmap = 'gray', interpolation = 'none')\n",
    "            axes[0].axis('off')\n",
    "            axes[1].axis('off')\n",
    "            plt.title(f'{49-idx} time step Jacobian')\n",
    "            plt.show()\n",
    "\n",
    "    patch_size_list = []\n",
    "    for idx, heatmap in enumerate(heatmaps_list):\n",
    "        patch_size = 0\n",
    "\n",
    "        heatmap_np = heatmap.cpu().detach().numpy()\n",
    "        heatmap_normalized = heatmap_np / heatmap_np.max()\n",
    "\n",
    "        threshold = 0.01\n",
    "        significant_pixels = (heatmap_normalized > threshold).sum()\n",
    "\n",
    "        h, w = heatmap_np.shape[1:]\n",
    "        y_indices, x_indices = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n",
    "\n",
    "        total_weight = heatmap_normalized.sum()\n",
    "\n",
    "        if total_weight > 0:  # Avoid division by zero\n",
    "            # Calculate weighted center of mass\n",
    "            center_y = np.sum(y_indices * heatmap_normalized) / total_weight\n",
    "            center_x = np.sum(x_indices * heatmap_normalized) / total_weight\n",
    "\n",
    "\n",
    "            # Calculate weighted standard deviation (measure of spread)\n",
    "            std_y = np.sqrt(np.sum(((y_indices - center_y)**2) * heatmap_normalized) / total_weight)\n",
    "            std_x = np.sqrt(np.sum(((x_indices - center_x)**2) * heatmap_normalized) / total_weight)\n",
    "\n",
    "            # Effective radius (in pixels)\n",
    "            effective_radius = np.mean([std_y, std_x]) * 2  # 2σ covers ~95% of influence\n",
    "            patch_size_list.append(effective_radius.item())\n",
    "        else:\n",
    "            effective_radius = 0\n",
    "\n",
    "    return patch_size_list\n",
    "\n",
    "\n",
    "def view_image(images):\n",
    "\n",
    "    all_images = torch.cat(list(images), dim=0)\n",
    "    fig, axes = plt.subplots(25, 40, figsize=(14, 14))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(all_images[i].cpu().squeeze().numpy(), cmap='gray')  # 차원 축소 후 출력\n",
    "        ax.axis('off')  # 축 숨김\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def view_one_image(images):\n",
    "\n",
    "    images = images.detach()\n",
    "    plt.imshow(images.cpu().squeeze().numpy(), cmap='gray', interpolation=\"nearest\")  # 차원 축소 후 출력\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def analyze_receptive_field_window_size(heatmap_list, threshold):\n",
    "    \"\"\"\n",
    "    Analyzes heatmaps to determine the p×p window size of the receptive field at each timestep.\n",
    "\n",
    "    Parameters:\n",
    "    - heatmap_list: List of gradient heatmaps from ddpm_sample_Jaco function\n",
    "    - times: List of corresponding timesteps\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping timesteps to p values (window sizes)\n",
    "    \"\"\"\n",
    "    receptive_field_sizes = {}\n",
    "    patch_size_list = []\n",
    "\n",
    "    for t, heatmap in enumerate(heatmap_list):\n",
    "        # Convert tensor to numpy for analysis\n",
    "        heatmap_np = heatmap[0].cpu().detach().abs().numpy()\n",
    "\n",
    "        # Normalize the heatmap\n",
    "        heatmap_normalized = heatmap_np / heatmap_np.max()\n",
    "\n",
    "        # Find significant gradient values (above threshold)\n",
    "\n",
    "        significant_mask = heatmap_normalized > threshold\n",
    "\n",
    "        # Find the bounding box of significant gradient values\n",
    "        y_indices, x_indices = np.where(significant_mask)\n",
    "\n",
    "        y_min, y_max = y_indices.min(), y_indices.max()\n",
    "        x_min, x_max = x_indices.min(), x_indices.max()\n",
    "\n",
    "        # Calculate height and width of the bounding box\n",
    "        height = y_max - y_min + 1\n",
    "        width = x_max - x_min + 1\n",
    "\n",
    "        # Take the maximum dimension to ensure we capture the full receptive field\n",
    "        p = max(height, width)\n",
    "\n",
    "        # Convert to odd-sized window (3×3, 5×5, 7×7, etc.) for consistency with the paper\n",
    "        p = max(3, (p // 2) * 2 + 1)\n",
    "\n",
    "        patch_size_list.append(p)\n",
    "\n",
    "\n",
    "    return patch_size_list\n",
    "\n",
    "def normalize_heatmaps(heatmaps):\n",
    "    for idx, heatmap in enumerate(heatmaps):\n",
    "        normalized_heatmap = heatmap / torch.max(heatmap)\n",
    "        heatmaps[idx] = normalized_heatmap\n",
    "\n",
    "    return heatmaps\n",
    "\n",
    "def calculate_average_heatmap(trainer, sampler_method = 'ddpm' , epoch = 100, thres_hold = 0.9):\n",
    "    device = trainer.device\n",
    "\n",
    "    total_heatmaps = torch.zeros((1000, 1, 28, 28), device = device, dtype = torch.float64)\n",
    "\n",
    "    for i in range(epoch):\n",
    "        start_point = torch.randn((1,1,28,28), device = device)\n",
    "        images, heatmaps, noise_list = trainer.ema.ema_model.sample_for_Jaco(img = start_point, i = 14, j = 14)\n",
    "        heatmaps = normalize_heatmaps(heatmaps)\n",
    "        total_heatmaps += torch.stack(heatmaps)\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            average_heatmaps = total_heatmaps / (i + 1)\n",
    "\n",
    "            average_heatmaps_list = list(average_heatmaps)\n",
    "\n",
    "            if sampler_method == 'ddpm':\n",
    "                patches = view_Jaco_ddpm(images, average_heatmaps_list, threshold=thres_hold, view_image = False)\n",
    "            elif sampler_method == 'ddim':\n",
    "                patches = view_Jaco_ddim(images, average_heatmaps_list, threshold=thres_hold, view_image = False)\n",
    "\n",
    "            ts = np.linspace(0.0, 1.0, len(patches))\n",
    "\n",
    "            # 꺾은선 그래프 그리기\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(ts, list(reversed(patches)))\n",
    "            plt.xlabel('X')\n",
    "            plt.ylabel('Y')\n",
    "            plt.title(f'thershold = {thres_hold}')\n",
    "\n",
    "            plt.ylim(0, 28)\n",
    "\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    return average_heatmaps"
   ],
   "id": "cbbc815c659e041b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T06:38:43.592957Z",
     "start_time": "2025-04-04T06:38:43.588437Z"
    }
   },
   "cell_type": "code",
   "source": "start = torch.randn((1,1,28,28), device=device)",
   "id": "7b7d1e30941b4a7a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:38:45.634643Z",
     "start_time": "2025-04-04T06:38:45.572369Z"
    }
   },
   "source": [
    "from compared_ddpm_v3 import Unet, GaussianDiffusion, Trainer\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataset_size = 60000\n",
    "num_res = 1\n",
    "resolutions = 2\n",
    "init_dim = 32\n",
    "\n",
    "\n",
    "unet = Unet(dim = init_dim, dim_mults=(1,2), channels = 1)\n",
    "folder = f'init{init_dim}resolutions{resolutions}size{dataset_size}res{num_res}'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "ds = torchvision.datasets.MNIST(root=\"/home/dataset/mnist\", train=True, transform=transform, download=False)\n",
    "\n",
    "\n",
    "# Subset으로 훈련 데이터 제한\n",
    "model = GaussianDiffusion(unet, image_size=28, sampling_timesteps=20)\n",
    "trainer = Trainer(model, folder, ds = ds, train_num_steps = 50000, save_and_sample_every = 5000, train_batch_size=128)\n",
    "trainer.load(30)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# 사용 예시\n",
    "total_params = count_parameters(unet)\n",
    "print(f'모델의 총 파라미터 수: {total_params:,}')\n",
    "#trainer.load(30)\n",
    "\n",
    "\n",
    "start = torch.randn((1,1,28,28), device=device)\n",
    "images, heatmaps, noise_list = trainer.ema.ema_model.sample_for_Jaco(img = start, i = 14, j = 14)\n",
    "\n",
    "\n",
    "view_one_image(images[-1])\n",
    "print(images[-1].max(), images[-1].min())\n",
    "\n",
    "'''\n",
    "average_heatmaps = calculate_average_heatmap(trainer, sampler_method = 'ddpm')\n",
    "'''\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ELS_2'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mELS_2\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mout_dated\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcompared_ddpm_v3\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Unet, GaussianDiffusion, Trainer\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m transforms\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'ELS_2'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T07:32:16.264046Z",
     "start_time": "2025-04-01T07:32:16.257666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import sys\n",
    "if 'ELS_machine' in sys.modules:\n",
    "    print('기존의 import된 ELS_machine Module이 제거되었습니다.')\n",
    "    del sys.modules['ELS_machine']\n",
    "if 'compared_ddpm' in sys.modules:\n",
    "    print('기존의 import된 compared_ddpm Module이 제거되었습니다.')\n",
    "    del sys.modules['compared_ddpm']\n",
    "if 'compared_ddpm_resnet' in sys.modules:\n",
    "    print('기존의 import된 compared_ddpm_resnet Module이 제거되었습니다.')\n",
    "    del sys.modules['compared_ddpm_resnet']\n"
   ],
   "id": "67669ba49877a975",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 import된 compared_ddpm Module이 제거되었습니다.\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "file_name =f\"{folder}/average_heatmaps.pth\"\n",
    "average_heatmaps = torch.load(file_name, weights_only=True)\n",
    "\n",
    "average_heatmaps_list = list(average_heatmaps)\n",
    "\n",
    "thres_hold = 0.9\n",
    "images=list(torch.randn((1000, 1, 28, 28), device = device))\n",
    "patches = view_Jaco_ddim(images, average_heatmaps_list, threshold=thres_hold, view_image = False)\n",
    "#patches = analyze_receptive_field_window_size(average_heatmaps_list, threshold = thres_hold)\n",
    "\n",
    "ts = np.linspace(0.0, 1.0, len(patches))\n",
    "\n",
    "# 꺾은선 그래프 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ts, list(reversed(patches)))\n",
    "plt.xlabel('Time (Forward Process)')\n",
    "plt.ylabel('Receptive Field')\n",
    "plt.title(f'UNet / thershold = {thres_hold}')\n",
    "\n",
    "plt.ylim(0, 28)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "b4b9193099448285",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from ELS_2.out_dated.compared_ddpm_version1 import Unet, GaussianDiffusion, Trainer\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "ds = torchvision.datasets.MNIST(root=\"/home/dataset/mnist\", train=True, transform=transform, download=False)\n",
    "num_samples = 1000\n",
    "subset_indices = list(range(num_samples))\n",
    "\n",
    "mnist_train_dataset = Subset(ds, subset_indices)\n",
    "\n",
    "unet = Unet(dim = 64, dim_mults=(1,2,4), channels = 1)\n",
    "folder = 'results_1000_256'\n",
    "\n",
    "model = GaussianDiffusion(unet, image_size=28, sampling_timesteps=1000)\n",
    "trainer = Trainer(model, folder, ds = mnist_train_dataset, train_num_steps = 100000, save_and_sample_every = 10000)\n",
    "trainer.load(5)\n",
    "\n",
    "trainer.ema.ema_model.eval()\n",
    "start_point = torch.randn((1,1,28,28), device=device)\n",
    "images, heatmaps, noise_list = trainer.ema.ema_model.sample_for_Jaco(img = start_point, i = 14, j = 14)\n",
    "view_Jaco_ddpm(images, heatmaps)\n",
    "\n",
    "unet = Unet(dim = 64, dim_mults=(1,2,4), channels = 1)\n",
    "folder = 'results_20000_256'\n",
    "\n",
    "model = GaussianDiffusion(unet, image_size=28, sampling_timesteps=1000)\n",
    "trainer = Trainer(model, folder, ds = mnist_train_dataset, train_num_steps = 100000, save_and_sample_every = 10000)\n",
    "trainer.load(5)\n",
    "\n",
    "trainer.ema.ema_model.eval()\n",
    "start_point = torch.randn((1,1,28,28), device=device)\n",
    "images1, heatmaps1, noise_list = trainer.ema.ema_model.sample_for_Jaco(img = start_point, i = 14, j = 14)\n",
    "view_Jaco_ddpm(images1, heatmaps1)\n",
    "\n",
    "'''\n",
    "heatmaps_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    heatmaps_list.append(torch.zeros((1,28,28), device = device, dtype = torch.long))\n",
    "\n",
    "for i in range(10):\n",
    "    images, heatmaps, noise_list = trainer.ema.ema_model.sample_for_Jaco(img = start_point, i = 14, j = 14)\n",
    "\n",
    "    for idx, heatmap in enumerate(heatmaps):\n",
    "        heatmaps_list[idx] = heatmaps_list[idx] + heatmap\n",
    "\n",
    "\n",
    "patch_size_list = analyze_receptive_field_window_size(heatmaps_list, list(np.arange(1000)))\n",
    "\n",
    "'''\n"
   ],
   "id": "1fe5de30371b07e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(torch.max(images[-1]), torch.min(images[-1]))\n",
    "print(torch.max(images1[-1]), torch.min(images1[-1]))\n",
    "print(images[-1])"
   ],
   "id": "65ecf323b1b60e58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ELS_2.out_dated.compared_ddpm_resnet import *\n",
    "\n",
    "unet = ResNet()\n",
    "model = GaussianDiffusion(unet, image_size=28, sampling_timesteps=50)\n",
    "folder = 'results_resnet'\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "ds = torchvision.datasets.MNIST(root=\"/home/dataset/mnist\", train=True, transform=transform, download=False)\n",
    "#num_samples = 1000\n",
    "#subset_indices = list(range(num_samples))  # 항상 0~999번째 샘플 사용\n",
    "\n",
    "# Subset으로 훈련 데이터 제한\n",
    "#mnist_train_dataset = Subset(ds, subset_indices)\n",
    "trainer = Trainer(model, folder, ds = ds, train_num_steps = 150000, save_and_sample_every = 10000, train_batch_size=128)\n",
    "trainer.train()\n"
   ],
   "id": "825c0210d4ebed5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cf45aaf8d0b36982",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
