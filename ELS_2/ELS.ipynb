{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:58:27.042745Z",
     "start_time": "2025-03-12T05:58:26.917163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "# 데이터 변환 정의 (텐서 변환 및 정규화)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# MNIST 데이터셋 다운로드\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"/home/dataset/mnist\", train=True, transform=transform, download=False)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "def loader(dl):\n",
    "    while True:\n",
    "        for dataset in dl:\n",
    "            yield dataset"
   ],
   "id": "a9a23c775b9af3a1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:58:31.232879Z",
     "start_time": "2025-03-12T05:58:31.219472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_beta_schedule(timesteps, s = 0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    t = torch.linspace(0, timesteps, steps, dtype = torch.float64) / timesteps\n",
    "    alphas_cumprod = torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    \"\"\"\n",
    "    linear schedule, proposed in original ddpm paper\n",
    "    \"\"\"\n",
    "    scale = 1000 / timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float64)\n",
    "\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "def gamma_cosine(t, lambda_val=2):\n",
    "    \"\"\"\n",
    "    Cosine schedule 기반 gamma_t 계산\n",
    "    t: 연속 시간 (0~1 사이)\n",
    "    lambda_val: Cosine decay의 steepness 조절 파라미터\n",
    "    \"\"\"\n",
    "    s_t = (torch.pi / 2) * t ** lambda_val  # s(t) = (pi/2) * t^lambda\n",
    "    sin_2s = torch.sin(2 * s_t)\n",
    "    cos2_s = torch.cos(s_t) ** 2\n",
    "    gamma_t = (torch.pi / 4) * lambda_val * t ** (lambda_val - 1) * (sin_2s / cos2_s)\n",
    "\n",
    "    return gamma_t\n",
    "\n"
   ],
   "id": "4f40441ea6e25032",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:58:32.771023Z",
     "start_time": "2025-03-12T05:58:32.759025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal\n",
    "import math\n",
    "\n",
    "class Schedule():\n",
    "    def __init__(self, device):\n",
    "        betas = linear_beta_schedule(1000)\n",
    "        self.betas = betas.to(device)\n",
    "\n",
    "        alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value = 1.)\n",
    "\n",
    "        self.one_minus_alphas_cumprod = 1. - self.alphas_cumprod\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = torch.log(1. - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.sqrt(1. / self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1. / self.alphas_cumprod - 1)\n",
    "\n",
    "        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "\n",
    "        self.posterior_log_variance_clipped = torch.log(self.posterior_variance.clamp(min =1e-20))\n",
    "        self.posterior_mean_coef1 = self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "        self.posterior_mean_coef2 = (1. - self.alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - self.alphas_cumprod)\n",
    "\n"
   ],
   "id": "48720c4997e0fc63",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:58:35.390768Z",
     "start_time": "2025-03-12T05:58:35.375097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def Weight_post(image_t, dataset, sqrt_at, one_minus_at):\n",
    "\n",
    "    b, *_ = dataset.shape\n",
    "\n",
    "    mse = (image_t - sqrt_at * dataset) ** 2\n",
    "    mse = mse.view(dataset.shape[0], -1).sum(dim=1)\n",
    "    one_minus_recip = - 1. / (2 * one_minus_at)\n",
    "    mse = mse * one_minus_recip\n",
    "\n",
    "    weight = F.softmax(mse, dim=0)\n",
    "\n",
    "    return weight.view(b, *((1,) * (len(dataset.shape) - 1)))\n"
   ],
   "id": "9bb4c37881bdd49a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:58:37.148763Z",
     "start_time": "2025-03-12T05:58:37.139089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def score_f_estimator(image_t, dataset, t, schedule, gene = None):\n",
    "    sqrt_at = schedule.sqrt_alphas_cumprod[t]\n",
    "    one_minus_at = schedule.one_minus_alphas_cumprod[t]\n",
    "    #sqrt_at = extract(schedule.sqrt_alphas_cumprod, t, image.shape).squeeze()\n",
    "    #one_minus_at = extract(schedule.one_minus_alphas_cumprod, t, image.shape).squeeze()\n",
    "\n",
    "    if gene is None:\n",
    "        image_t = image_t * sqrt_at + noise * sqrt_one_minus_at\n",
    "    weight_schedule = Weight_post(image_t, dataset, sqrt_at, one_minus_at)\n",
    "\n",
    "    one_recip = -1. / one_minus_at\n",
    "\n",
    "    score = (image_t - sqrt_at * dataset) * weight_schedule\n",
    "\n",
    "    score = score * one_recip\n",
    "\n",
    "    score = torch.sum(score, dim=0).unsqueeze(0)\n",
    "\n",
    "    return score, max(weight_schedule), torch.argmax(weight_schedule)\n",
    "\n"
   ],
   "id": "bb44e506c411513f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T02:51:40.147318Z",
     "start_time": "2025-03-12T02:51:40.140543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # \"cuda\" 또는 \"cpu\""
   ],
   "id": "f82f4c5345e284c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T02:51:50.253675Z",
     "start_time": "2025-03-12T02:51:50.245409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # 첫 번째 GPU 사용\n",
    "    print(f\"Using device: {device}\")"
   ],
   "id": "342475c64be615f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T02:51:58.171598Z",
     "start_time": "2025-03-12T02:51:58.165436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))  # 첫 번째 GPU의 이름 출력"
   ],
   "id": "99c6b49039151fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A40\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24dacb85dea91b35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
